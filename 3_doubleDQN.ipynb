{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## double DQN\n",
    "传统的DQN 存在会高估action的Q值的问题，并且这种高估会随着action的个数的增长而变大。\n",
    "\n",
    "double DQN 可以一定程度上克服这一点\n",
    "#### original DQN\n",
    "$${TargetQ{\\rm = r + }}\\gamma \\mathop {{\\rm{max}}}\\limits_{a'} Q(s',a'|{\\theta ^{tar}})$$\n",
    "$${evalQ{\\rm = }}Q(s,a|{\\theta ^{eval}})$$\n",
    "$$L({\\theta ^{eval}}) = abs(evalQ - TargetQ)$$\n",
    "#### double DQN \n",
    "$$TargetQ{\\rm{ = r + }}\\gamma Q(s',\\mathop {\\max }\\limits_{a'} Q(s',a'|{\\theta ^{eval}})|{\\theta ^{tar}})$$\n",
    "$$evalQ{\\rm{ = }}Q(s,a|{\\theta ^{eval}})$$\n",
    "$$L({\\theta ^{eval}}) = abs(evalQ - TargetQ)$$\n",
    "\n",
    "${\\theta ^{eval}}$ 是evalnet的参数，${\\theta ^{tar}}$ 是targetnet 的参数\n",
    "\n",
    "由上述公式可以看出，Double DQN 和 original DQN 不一样的地方就在于在计算targetQ时，original DQN 使用贪婪方法每个都取targetnet输出最大值对应的action，而double DQN 则选择 evalnet 输出最大值对应的action（这样选出来的action不一定是targetnet输出q值最大的action），然后在计算对应的targetQ。\n",
    "\n",
    "## reference：\n",
    "https://blog.csdn.net/u013236946/article/details/73161586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from atari_wrappers import make_atari, wrap_deepmind,LazyFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "def prepro(obs):\n",
    "    \"\"\"\n",
    "    preprocess observation \n",
    "    [84,84,4]=>[4,84,84]\n",
    "    \"\"\"\n",
    "    obs = obs._force().transpose(2,0,1)/255  # 0-255 => 0-1, [84,84,4] => [4,84,84]\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (linear1): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (linear2): Linear(in_features=512, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# net\n",
    "import torch\n",
    "from torch import nn\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Initialize a deep Q-learning network as described in\n",
    "    https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
    "    Arguments:\n",
    "        in_channels: number of channel of input.\n",
    "            i.e The number of most recent frames stacked together as describe in the paper\n",
    "        out_num: number of action-value to output, one-to-one correspondence to action in game.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel=4, out_num=6):\n",
    "        super(Net,self).__init__()\n",
    "        # layer setting paramters\n",
    "        layers = [32,64,64]\n",
    "        # output_size = (input_size-kernel_size)/stride + 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel,layers[0],kernel_size=8,stride=4), # [batch,4,84,84]=>[batch,layers[0],20,20] \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(layers[0],layers[1],kernel_size=4,stride=2), # [batch,layers[0],20,20]=>[batch,layers[1],9,9]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(layers[1],layers[2],kernel_size=3,stride=1), # [batch,layers[1],9,9]=>[batch,layers[2],7,7]\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(7*7*layers[2], 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear2 = nn.Linear(512, out_num)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # flatten\n",
    "        x = x.reshape(x.size(0), -1)  # [batch, layers[2],7,7]=>[batch,layers[2]*7*7]\n",
    "        x = self.linear1(x)\n",
    "        y = self.linear2(x)\n",
    "        # y = F.softmax(y)  # turn to probability\n",
    "        return y\n",
    "pre_net = Net()\n",
    "print(pre_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree():\n",
    "    data_point = 0  # data idx\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity  # num of leaves\n",
    "        self.tree = np.zeros(capacity*2-1)\n",
    "        self.transition = np.zeros(capacity, dtype=object) # save data\n",
    "        self.n_entries = 0\n",
    "        \n",
    "    def total_p(self):\n",
    "        return self.tree[0]  # return the 0 node\n",
    "        \n",
    "    def add(self, p, data):\n",
    "        # add data and priority\n",
    "        # p: priority, data \n",
    "        idx = self.data_point + self.capacity -1\n",
    "        self.transition[self.data_point] = data   # save data        \n",
    "        self.data_point += 1\n",
    "        if self.data_point >= self.capacity:\n",
    "            self.data_point = 0            \n",
    "        \n",
    "        change = p - self.tree[idx]   \n",
    "        self.tree[idx] = p            # save priority\n",
    "        self.n_entries += 1   # count num of entries\n",
    "        \n",
    "        # propagation  update parents nodes\n",
    "        p_idx = (idx-1)//2  # parent idx\n",
    "        while True:           \n",
    "            self.tree[p_idx] += change\n",
    "            if p_idx != 0:\n",
    "                p_idx = (p_idx-1)//2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def update(self,idx, p):\n",
    "        # update tree\n",
    "        change = p - self.tree[idx]\n",
    "        self.tree[idx] = p  # change priority in leaves node        \n",
    "        # update parents node\n",
    "        p_idx = (idx-1)//2   #\n",
    "        while True:            \n",
    "            self.tree[p_idx] += change\n",
    "            if p_idx != 0:\n",
    "                p_idx = (p_idx-1)//2\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def retrieve(self, p_idx, s):\n",
    "        # search leaf idx for s        \n",
    "        while True:\n",
    "            l_idx = p_idx*2 + 1  # left child idx\n",
    "            r_idx = l_idx +1     # right child idx  \n",
    "            if l_idx >= self.capacity*2-1: # 其子节点超出，结点序号范围， 说明已经是叶子结点\n",
    "                return p_idx \n",
    "            if self.tree[l_idx] >= s:\n",
    "                p_idx = l_idx\n",
    "            else:\n",
    "                p_idx = r_idx\n",
    "                s -= self.tree[l_idx]\n",
    "            \n",
    "    def get(self, s):\n",
    "        # get a data and priority from tree and transition        \n",
    "        # get idx of leaves\n",
    "        idx = self.retrieve(0,s)\n",
    "        priority = self.tree[idx]\n",
    "        data_idx = idx - (self.capacity - 1)\n",
    "        data = self.transition[data_idx]\n",
    "        return idx, priority, data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory buffer replay\n",
    "class Memory_buffer_replay():\n",
    "    beta = 0.4\n",
    "    beta_increment_per_sampling = 0.001\n",
    "    abs_err_upper = 1.\n",
    "    def __init__(self, capacity, device):\n",
    "        self.capacity = capacity\n",
    "        self.sumtree = SumTree(self.capacity)\n",
    "        self.device = device\n",
    "        \n",
    "        self.e = 0.01\n",
    "        self.a = 0.6\n",
    "        self.prio_max = 0.1\n",
    "        \n",
    "    def store_record(self, state, state_next, a, r, done):\n",
    "        data = (state, state_next, a, r, done)\n",
    "        priority = (np.abs(self.prio_max) + self.e) ** self.a #  proportional priority\n",
    "        self.sumtree.add(priority, data) # save p, data in sumtree\n",
    "        \n",
    "    def sample(self, batchsz):\n",
    "        states, state_nexts, a_s, r_s, done_s = [],[],[],[],[]\n",
    "        idxs, ps, isweights = [],[],[]  # idss, prioritys\n",
    "        segment = self.sumtree.total_p()/batchsz\n",
    "        \n",
    "        self.beta = np.min([1., self.beta+self.beta_increment_per_sampling])\n",
    "        min_prob = np.min(self.sumtree.tree[-self.capacity:])/self.sumtree.total_p()\n",
    "        \n",
    "        for i in range(batchsz):\n",
    "            down_bound = i*segment\n",
    "            up_bound = (i+1)*segment\n",
    "            s = np.random.uniform(down_bound, up_bound)\n",
    "            idx, p, data = self.sumtree.get(s) \n",
    "            \n",
    "            state, state_next, a, r, done = data\n",
    "            prob = p/self.sumtree.total_p()\n",
    "            isweight = np.power(prob/min_prob, -self.beta)\n",
    "            \n",
    "            isweights.append(isweight)\n",
    "            idxs.append(idx)\n",
    "            ps.append(p)\n",
    "            states.append(state)\n",
    "            state_nexts.append(state_next)\n",
    "            a_s.append(a)\n",
    "            r_s.append(r)\n",
    "            done_s.append(done)\n",
    "        \n",
    "        #from list to numpy\n",
    "#         idxs, ps = np.array(idxs), np.array(ps)\n",
    "        # function: list=> tensor\n",
    "        list2tensor = lambda data: torch.from_numpy(np.array(data)).to(self.device)\n",
    "        \n",
    "        isweights = list2tensor(isweights)\n",
    "        states, state_nexts = list2tensor(states), list2tensor(state_nexts)\n",
    "        a_s, r_s, done_s = list2tensor(a_s), list2tensor(r_s), list2tensor(done_s)\n",
    "        # isweights: tensor, idx:list, ps:list, states:tensor, as, rs, done_s:tensor\n",
    "        return isweights, idxs, ps, states, state_nexts, a_s, r_s, done_s\n",
    "    \n",
    "    def update(self, idxs, errors):\n",
    "        # update data priority\n",
    "        self.prio_max = max(self.prio_max, max(np.abs(errors)))\n",
    "        for i, idx in enumerate(idxs):\n",
    "            p = (np.abs(errors[i]) + self.e) ** self.a\n",
    "            self.sumtree.update(idx, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN with priority\n",
    "import torch.nn.functional as F\n",
    "class DDQN_priority():\n",
    "    def __init__(self, args, env, load_model=False):        \n",
    "        # use cuda\n",
    "        cuda = True\n",
    "        if cuda:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            \n",
    "        # env\n",
    "        self.env = env\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.dim_shape = env.observation_space.shape\n",
    "        \n",
    "        # hyperparams\n",
    "        self.capacity = 100000\n",
    "        self.decay = 0.99\n",
    "        self.episodes = args.episodes\n",
    "        self.log_interval = args.log_interval  # print state per log_interval epsisode\n",
    "        self.save_interval = args.save_interval  # interval for save model \n",
    "        \n",
    "        self.epilon_max = 1\n",
    "        self.epilon_min = 0.01\n",
    "        self.learning_start = 10000  # 装满10000 再开始\n",
    "        self.epilon_decay = 30000\n",
    "        \n",
    "        # learn params\n",
    "        self.lr = args.lr\n",
    "        self.batchsz = args.batchsz\n",
    "        self.iter =0\n",
    "        self.iter_max = args.iter_max\n",
    "        \n",
    "        # build model\n",
    "        self.eval_model = Net().to(self.device)\n",
    "        self.tar_model = Net().to(self.device)  \n",
    "        # load model\n",
    "        if load_model:\n",
    "            self.eval_model.load_state_dict(torch.load('dqn_priority.mdl'))\n",
    "        self.tar_model.load_state_dict(self.eval_model.state_dict())\n",
    "        # build optimizer\n",
    "        self.optimizer = optim.RMSprop(self.eval_model.parameters(),lr=self.lr, eps=0.001, alpha=0.95)\n",
    "#         self.optimizer = optim.Adam(self.eval_model.parameters(), self.lr)\n",
    "#         self.cost_F = nn.MSELoss()\n",
    "        \n",
    "        # build memory buffer\n",
    "        self.buffer = Memory_buffer_replay(self.capacity, self.device)\n",
    "    \n",
    "    def train(self):\n",
    "        episodes = self.episodes\n",
    "        losses = []\n",
    "        rewards  = []\n",
    "        \n",
    "        # decay function explot ratio\n",
    "        epilon_by_g_step = lambda step_idx:self.epilon_min + (self.epilon_max-self.epilon_min)*np.exp(-1*step_idx/self.epilon_decay)\n",
    "        # global step\n",
    "        global_step = 0\n",
    "        \n",
    "        for epis in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            state = prepro(state) # [84,84,4]=>[4,84,84]\n",
    "            reward_sum = 0\n",
    "            loss_ = []\n",
    "            # decay explot ratio\n",
    "#             self.explot_ep = self.explot_ep_min + (self.explot_ep_max-self.explot_ep_min)*np.exp(-1*epis/50.)\n",
    "            while True:\n",
    "                # decay explot ratio\n",
    "                epsilon = epilon_by_g_step(global_step)\n",
    "                global_step += 1 \n",
    "                act = self.make_action(state, epsilon) # choose action\n",
    "                state_next, r, done, inf = self.env.step(act)\n",
    "                state_next = prepro(state_next)\n",
    "                reward_sum += r                \n",
    "                # store data\n",
    "                self.buffer.store_record(state, state_next, act, r, done)                \n",
    "                if done:                    \n",
    "                    rewards.append(reward_sum)\n",
    "                    losses.append(np.mean(loss_))\n",
    "                    break  # start another episode\n",
    "                else:\n",
    "                    state = state_next\n",
    "            \n",
    "                # learn model\n",
    "                if self.buffer.sumtree.n_entries == self.learning_start:\n",
    "                    print('#'*30 + 'start learning' + '#'*30)\n",
    "                if self.buffer.sumtree.n_entries > self.learning_start:\n",
    "                    loss = self.learn()\n",
    "                    loss_.append(loss)\n",
    "                else:\n",
    "                    loss_.append(0)\n",
    "                \n",
    "            # print train state\n",
    "            if epis%self.log_interval==0 and epis>0:\n",
    "                #print(losses)\n",
    "                print('global step:{}'.format(global_step-1),\n",
    "                      'episode :{}/{}'.format(epis, self.episodes), \n",
    "                      'aver loss:{:.5f}'.format(np.mean(losses[-10:])), \n",
    "                      'aver reward:{:.5f}'.format(np.mean(rewards[-10:])),\n",
    "                      'explot:{:.5f}'.format(epsilon)\n",
    "                     )\n",
    "            # save model\n",
    "            if epis%self.save_interval==0 and epis>0:\n",
    "                torch.save(self.eval_model.state_dict(),'dqn_priority.mdl')\n",
    "        return losses, rewards\n",
    "    \n",
    "    def learn(self):\n",
    "        # learn the model\n",
    "        \n",
    "        # get data,  idxs, ps : list. others tensor\n",
    "        isweights, idxs, ps, state, state_next, act_s, r_s, done_s = self.buffer.sample(self.batchsz)        \n",
    "        \n",
    "        # pre\n",
    "        eval_q = self.eval_model(state.float()).gather(1,act_s.unsqueeze(1).long())  # get pre and choose Q with act_c,[batch,1]\n",
    "        eval_q = eval_q.squeeze(-1)  # [batch,1] => [batch]\n",
    "        \n",
    "        ####################### part different with original DQN #######################\n",
    "        # compute label\n",
    "        next_q = self.tar_model(state_next.float()).detach() # not update so use detach\n",
    "        # choose action from eval_model\n",
    "        next_q_eval = self.eval_model(state_next.float()).detach()\n",
    "        action_eval = next_q_eval.max(1)[1]  # return idx of max Q, action:=idx\n",
    "        # choose q with chosen action\n",
    "        next_max_q = next_q.gather(1,action_eval.unsqueeze(1).long())  \n",
    "        next_max_q = next_max_q.squeeze(-1)\n",
    "        ################################################################################\n",
    "        \n",
    "        decay = torch.tensor(self.decay).float().to(self.device)\n",
    "        tar_q = r_s.float() + decay*next_max_q\n",
    "        tar_q = torch.where(done_s>0, r_s.float(), tar_q)  # Q_next = r when done is true\n",
    "        \n",
    "        #compute td-loss\n",
    "        loss = F.smooth_l1_loss(eval_q, tar_q)\n",
    "#         loss = torch.mean(isweights*(eval_q - tar_q)**2) # loss expect input dim=[batch,1]\n",
    "        # update buffer with error\n",
    "        errors = (eval_q - tar_q).detach().cpu().tolist()\n",
    "        self.buffer.update(idxs, errors)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # clip gradient\n",
    "        for param in self.eval_model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # update tar_model\n",
    "        self.iter += 1\n",
    "        if self.iter%self.iter_max==0:\n",
    "            self.tar_model.load_state_dict(self.eval_model.state_dict())\n",
    "        \n",
    "        return loss.cpu().item() # ruturn mean loss\n",
    "    \n",
    "    def make_action(self, state, epsilon=None):\n",
    "        state = torch.from_numpy(state).float()\n",
    "        \n",
    "        pre_q = self.eval_model(state.unsqueeze(0).to(self.device))\n",
    "        pre_q = pre_q.cpu().detach()\n",
    "        \n",
    "        #explot_ep = self.explot_ep_min + (self.explot_ep_max-self.explot_ep_min)*np.exp(-1*epis/20.)\n",
    "        if epsilon==None:\n",
    "            epsilon=self.epsion_min\n",
    "        if np.random.uniform()< epsilon:\n",
    "            action = np.random.choice(self.n_actions) # random choose action\n",
    "        else:\n",
    "            action = torch.argmax(pre_q)\n",
    "            action = action.item()\n",
    "        return action     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument\n",
    "class Argument():\n",
    "    def __init__(self):\n",
    "        self.lr = 1e-3\n",
    "        self.batchsz = 32\n",
    "        \n",
    "        self.episodes = 210\n",
    "        \n",
    "        self.log_interval = 1 # print state per log_interval epsisode\n",
    "        self.save_interval = 20  # interval for save model\n",
    "        \n",
    "        self.iter_max = 1000  # update tar_model interval\n",
    "\n",
    "args = Argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step:2149 episode :1/210 aver loss:0.00000 aver reward:-19.50000 explot:0.93156\n",
      "global step:2981 episode :2/210 aver loss:0.00000 aver reward:-20.00000 explot:0.90636\n",
      "global step:3893 episode :3/210 aver loss:0.00000 aver reward:-20.00000 explot:0.87952\n",
      "global step:4837 episode :4/210 aver loss:0.00000 aver reward:-20.20000 explot:0.85258\n",
      "global step:5592 episode :5/210 aver loss:0.00000 aver reward:-20.33333 explot:0.83164\n",
      "global step:6495 episode :6/210 aver loss:0.00000 aver reward:-20.42857 explot:0.80728\n",
      "global step:7449 episode :7/210 aver loss:0.00000 aver reward:-20.37500 explot:0.78232\n",
      "global step:8575 episode :8/210 aver loss:0.00000 aver reward:-20.33333 explot:0.75387\n",
      "global step:9598 episode :9/210 aver loss:0.00000 aver reward:-20.40000 explot:0.72894\n",
      "##############################start learning##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryzen/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step:10435 episode :10/210 aver loss:0.00157 aver reward:-20.40000 explot:0.70915\n",
      "global step:11391 episode :11/210 aver loss:0.00589 aver reward:-20.50000 explot:0.68723\n",
      "global step:12301 episode :12/210 aver loss:0.00999 aver reward:-20.40000 explot:0.66699\n",
      "global step:13225 episode :13/210 aver loss:0.01166 aver reward:-20.40000 explot:0.64706\n",
      "global step:14278 episode :14/210 aver loss:0.01224 aver reward:-20.30000 explot:0.62509\n",
      "global step:15155 episode :15/210 aver loss:0.01279 aver reward:-20.30000 explot:0.60737\n",
      "global step:16071 episode :16/210 aver loss:0.01345 aver reward:-20.20000 explot:0.58941\n",
      "global step:17029 episode :17/210 aver loss:0.01425 aver reward:-20.20000 explot:0.57120\n",
      "global step:17819 episode :18/210 aver loss:0.01496 aver reward:-20.30000 explot:0.55661\n",
      "global step:18892 episode :19/210 aver loss:0.01572 aver reward:-20.00000 explot:0.53741\n",
      "global step:20016 episode :20/210 aver loss:0.01496 aver reward:-20.00000 explot:0.51801\n",
      "global step:20777 episode :21/210 aver loss:0.01148 aver reward:-20.10000 explot:0.50529\n",
      "global step:21599 episode :22/210 aver loss:0.00813 aver reward:-20.20000 explot:0.49190\n",
      "global step:22598 episode :23/210 aver loss:0.00712 aver reward:-20.30000 explot:0.47612\n",
      "global step:23850 episode :24/210 aver loss:0.00716 aver reward:-20.10000 explot:0.45707\n",
      "global step:24789 episode :25/210 aver loss:0.00720 aver reward:-20.10000 explot:0.44329\n",
      "global step:25848 episode :26/210 aver loss:0.00712 aver reward:-20.20000 explot:0.42826\n",
      "global step:26909 episode :27/210 aver loss:0.00684 aver reward:-20.20000 explot:0.41373\n",
      "global step:28238 episode :28/210 aver loss:0.00664 aver reward:-20.10000 explot:0.39623\n",
      "global step:29548 episode :29/210 aver loss:0.00639 aver reward:-20.10000 explot:0.37973\n",
      "global step:30872 episode :30/210 aver loss:0.00608 aver reward:-20.00000 explot:0.36377\n",
      "global step:32502 episode :31/210 aver loss:0.00599 aver reward:-19.60000 explot:0.34506\n",
      "global step:33510 episode :32/210 aver loss:0.00611 aver reward:-19.50000 explot:0.33399\n",
      "global step:34747 episode :33/210 aver loss:0.00621 aver reward:-19.40000 explot:0.32090\n",
      "global step:36496 episode :34/210 aver loss:0.00620 aver reward:-19.10000 explot:0.30329\n",
      "global step:37842 episode :35/210 aver loss:0.00614 aver reward:-19.00000 explot:0.29042\n",
      "global step:38954 episode :36/210 aver loss:0.00612 aver reward:-18.80000 explot:0.28022\n",
      "global step:40788 episode :37/210 aver loss:0.00622 aver reward:-18.70000 explot:0.26420\n",
      "global step:43001 episode :38/210 aver loss:0.00631 aver reward:-18.20000 explot:0.24612\n",
      "global step:44499 episode :39/210 aver loss:0.00640 aver reward:-18.40000 explot:0.23462\n",
      "global step:46363 episode :40/210 aver loss:0.00651 aver reward:-18.00000 explot:0.22109\n",
      "global step:48238 episode :41/210 aver loss:0.00638 aver reward:-18.00000 explot:0.20830\n",
      "global step:50441 episode :42/210 aver loss:0.00620 aver reward:-17.50000 explot:0.19426\n",
      "global step:52620 episode :43/210 aver loss:0.00621 aver reward:-17.20000 explot:0.18135\n",
      "global step:54409 episode :44/210 aver loss:0.00630 aver reward:-17.30000 explot:0.17143\n",
      "global step:56382 episode :45/210 aver loss:0.00649 aver reward:-17.10000 explot:0.16115\n",
      "global step:58788 episode :46/210 aver loss:0.00659 aver reward:-16.80000 explot:0.14951\n",
      "global step:61053 episode :47/210 aver loss:0.00659 aver reward:-16.30000 explot:0.13936\n",
      "global step:62992 episode :48/210 aver loss:0.00653 aver reward:-16.50000 explot:0.13126\n",
      "global step:65001 episode :49/210 aver loss:0.00655 aver reward:-16.10000 explot:0.12341\n",
      "global step:67018 episode :50/210 aver loss:0.00651 aver reward:-16.20000 explot:0.11604\n",
      "global step:69240 episode :51/210 aver loss:0.00637 aver reward:-15.90000 explot:0.10847\n",
      "global step:71723 episode :52/210 aver loss:0.00618 aver reward:-15.80000 explot:0.10064\n",
      "global step:73778 episode :53/210 aver loss:0.00591 aver reward:-15.70000 explot:0.09464\n",
      "global step:76818 episode :54/210 aver loss:0.00570 aver reward:-15.00000 explot:0.08649\n",
      "global step:79120 episode :55/210 aver loss:0.00544 aver reward:-14.60000 explot:0.08084\n",
      "global step:81353 episode :56/210 aver loss:0.00521 aver reward:-14.70000 explot:0.07576\n",
      "global step:83902 episode :57/210 aver loss:0.00506 aver reward:-14.60000 explot:0.07040\n",
      "global step:87080 episode :58/210 aver loss:0.00496 aver reward:-14.00000 explot:0.06433\n",
      "global step:89839 episode :59/210 aver loss:0.00479 aver reward:-13.80000 explot:0.05955\n",
      "global step:93025 episode :60/210 aver loss:0.00464 aver reward:-13.40000 explot:0.05456\n",
      "global step:95314 episode :61/210 aver loss:0.00457 aver reward:-13.60000 explot:0.05129\n",
      "global step:98000 episode :62/210 aver loss:0.00450 aver reward:-13.60000 explot:0.04775\n",
      "global step:100577 episode :63/210 aver loss:0.00442 aver reward:-13.30000 explot:0.04464\n",
      "global step:103304 episode :64/210 aver loss:0.00433 aver reward:-14.10000 explot:0.04163\n",
      "global step:105601 episode :65/210 aver loss:0.00427 aver reward:-14.40000 explot:0.03930\n",
      "global step:108238 episode :66/210 aver loss:0.00425 aver reward:-14.10000 explot:0.03684\n",
      "global step:111261 episode :67/210 aver loss:0.00419 aver reward:-13.70000 explot:0.03426\n",
      "global step:113962 episode :68/210 aver loss:0.00418 aver reward:-13.60000 explot:0.03218\n",
      "global step:116121 episode :69/210 aver loss:0.00417 aver reward:-13.80000 explot:0.03064\n",
      "global step:119052 episode :70/210 aver loss:0.00413 aver reward:-13.80000 explot:0.02871\n",
      "global step:122589 episode :71/210 aver loss:0.00411 aver reward:-12.70000 explot:0.02663\n",
      "global step:126413 episode :72/210 aver loss:0.00412 aver reward:-11.90000 explot:0.02464\n",
      "global step:128834 episode :73/210 aver loss:0.00417 aver reward:-12.00000 explot:0.02351\n",
      "global step:132454 episode :74/210 aver loss:0.00421 aver reward:-10.40000 explot:0.02197\n",
      "global step:135843 episode :75/210 aver loss:0.00421 aver reward:-9.30000 explot:0.02069\n",
      "global step:139294 episode :76/210 aver loss:0.00418 aver reward:-8.20000 explot:0.01953\n",
      "global step:142230 episode :77/210 aver loss:0.00425 aver reward:-8.40000 explot:0.01864\n",
      "global step:145962 episode :78/210 aver loss:0.00426 aver reward:-7.30000 explot:0.01763\n",
      "global step:149169 episode :79/210 aver loss:0.00426 aver reward:-6.20000 explot:0.01686\n",
      "global step:151564 episode :80/210 aver loss:0.00433 aver reward:-6.60000 explot:0.01633\n",
      "global step:155343 episode :81/210 aver loss:0.00439 aver reward:-6.30000 explot:0.01558\n",
      "global step:157618 episode :82/210 aver loss:0.00437 aver reward:-7.10000 explot:0.01517\n",
      "global step:161221 episode :83/210 aver loss:0.00429 aver reward:-6.40000 explot:0.01459\n",
      "global step:164761 episode :84/210 aver loss:0.00423 aver reward:-7.00000 explot:0.01408\n",
      "global step:168256 episode :85/210 aver loss:0.00422 aver reward:-6.10000 explot:0.01363\n",
      "global step:171765 episode :86/210 aver loss:0.00424 aver reward:-5.30000 explot:0.01323\n",
      "global step:175083 episode :87/210 aver loss:0.00418 aver reward:-4.30000 explot:0.01289\n",
      "global step:177811 episode :88/210 aver loss:0.00418 aver reward:-3.30000 explot:0.01264\n",
      "global step:180889 episode :89/210 aver loss:0.00418 aver reward:-2.20000 explot:0.01238\n",
      "global step:183206 episode :90/210 aver loss:0.00417 aver reward:-1.80000 explot:0.01221\n",
      "global step:186431 episode :91/210 aver loss:0.00413 aver reward:-0.90000 explot:0.01198\n",
      "global step:190211 episode :92/210 aver loss:0.00418 aver reward:0.40000 explot:0.01175\n",
      "global step:192414 episode :93/210 aver loss:0.00425 aver reward:2.50000 explot:0.01162\n",
      "global step:195156 episode :94/210 aver loss:0.00431 aver reward:4.40000 explot:0.01148\n",
      "global step:198262 episode :95/210 aver loss:0.00430 aver reward:4.60000 explot:0.01134\n",
      "global step:201227 episode :96/210 aver loss:0.00428 aver reward:4.30000 explot:0.01121\n",
      "global step:203792 episode :97/210 aver loss:0.00419 aver reward:5.30000 explot:0.01111\n",
      "global step:207099 episode :98/210 aver loss:0.00412 aver reward:3.80000 explot:0.01099\n",
      "global step:209567 episode :99/210 aver loss:0.00404 aver reward:4.30000 explot:0.01092\n",
      "global step:211684 episode :100/210 aver loss:0.00397 aver reward:7.00000 explot:0.01085\n",
      "global step:214717 episode :101/210 aver loss:0.00389 aver reward:6.50000 explot:0.01077\n",
      "global step:216936 episode :102/210 aver loss:0.00377 aver reward:8.20000 explot:0.01072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step:219616 episode :103/210 aver loss:0.00363 aver reward:7.70000 explot:0.01066\n",
      "global step:221988 episode :104/210 aver loss:0.00352 aver reward:7.70000 explot:0.01061\n",
      "global step:224171 episode :105/210 aver loss:0.00350 aver reward:8.70000 explot:0.01056\n",
      "global step:226230 episode :106/210 aver loss:0.00347 aver reward:10.30000 explot:0.01053\n",
      "global step:228377 episode :107/210 aver loss:0.00347 aver reward:10.90000 explot:0.01049\n",
      "global step:230156 episode :108/210 aver loss:0.00341 aver reward:13.20000 explot:0.01046\n",
      "global step:232210 episode :109/210 aver loss:0.00335 aver reward:13.80000 explot:0.01043\n",
      "global step:234529 episode :110/210 aver loss:0.00327 aver reward:13.60000 explot:0.01040\n",
      "global step:236697 episode :111/210 aver loss:0.00322 aver reward:15.20000 explot:0.01037\n",
      "global step:238545 episode :112/210 aver loss:0.00316 aver reward:15.50000 explot:0.01035\n",
      "global step:240353 episode :113/210 aver loss:0.00311 aver reward:16.50000 explot:0.01033\n",
      "global step:242348 episode :114/210 aver loss:0.00302 aver reward:17.10000 explot:0.01031\n",
      "global step:244071 episode :115/210 aver loss:0.00287 aver reward:17.60000 explot:0.01029\n",
      "global step:245976 episode :116/210 aver loss:0.00278 aver reward:17.50000 explot:0.01027\n",
      "global step:248723 episode :117/210 aver loss:0.00269 aver reward:17.30000 explot:0.01025\n",
      "global step:250355 episode :118/210 aver loss:0.00263 aver reward:17.50000 explot:0.01024\n",
      "global step:252517 episode :119/210 aver loss:0.00257 aver reward:17.40000 explot:0.01022\n",
      "global step:254392 episode :120/210 aver loss:0.00253 aver reward:17.80000 explot:0.01021\n",
      "global step:256677 episode :121/210 aver loss:0.00248 aver reward:17.70000 explot:0.01019\n",
      "global step:258742 episode :122/210 aver loss:0.00243 aver reward:17.40000 explot:0.01018\n",
      "global step:260683 episode :123/210 aver loss:0.00239 aver reward:17.40000 explot:0.01017\n",
      "global step:262596 episode :124/210 aver loss:0.00236 aver reward:17.40000 explot:0.01016\n",
      "global step:264318 episode :125/210 aver loss:0.00235 aver reward:17.30000 explot:0.01015\n",
      "global step:266445 episode :126/210 aver loss:0.00232 aver reward:17.20000 explot:0.01014\n",
      "global step:268539 episode :127/210 aver loss:0.00228 aver reward:17.40000 explot:0.01013\n",
      "global step:270309 episode :128/210 aver loss:0.00223 aver reward:17.20000 explot:0.01012\n",
      "global step:272142 episode :129/210 aver loss:0.00218 aver reward:17.60000 explot:0.01011\n",
      "global step:274189 episode :130/210 aver loss:0.00216 aver reward:17.10000 explot:0.01011\n",
      "global step:275943 episode :131/210 aver loss:0.00212 aver reward:17.40000 explot:0.01010\n",
      "global step:277777 episode :132/210 aver loss:0.00210 aver reward:17.70000 explot:0.01009\n",
      "global step:279712 episode :133/210 aver loss:0.00207 aver reward:17.70000 explot:0.01009\n",
      "global step:281714 episode :134/210 aver loss:0.00206 aver reward:17.50000 explot:0.01008\n",
      "global step:283523 episode :135/210 aver loss:0.00205 aver reward:17.50000 explot:0.01008\n",
      "global step:285471 episode :136/210 aver loss:0.00204 aver reward:17.60000 explot:0.01007\n",
      "global step:287139 episode :137/210 aver loss:0.00203 aver reward:18.10000 explot:0.01007\n",
      "global step:289037 episode :138/210 aver loss:0.00203 aver reward:18.00000 explot:0.01006\n",
      "global step:291030 episode :139/210 aver loss:0.00202 aver reward:17.40000 explot:0.01006\n",
      "global step:292817 episode :140/210 aver loss:0.00198 aver reward:18.10000 explot:0.01006\n",
      "global step:294548 episode :141/210 aver loss:0.00196 aver reward:18.10000 explot:0.01005\n",
      "global step:296684 episode :142/210 aver loss:0.00193 aver reward:17.70000 explot:0.01005\n",
      "global step:298559 episode :143/210 aver loss:0.00190 aver reward:17.70000 explot:0.01005\n",
      "global step:300672 episode :144/210 aver loss:0.00185 aver reward:17.60000 explot:0.01004\n",
      "global step:302388 episode :145/210 aver loss:0.00182 aver reward:17.60000 explot:0.01004\n",
      "global step:304108 episode :146/210 aver loss:0.00176 aver reward:17.90000 explot:0.01004\n",
      "global step:305830 episode :147/210 aver loss:0.00170 aver reward:17.90000 explot:0.01004\n",
      "global step:308101 episode :148/210 aver loss:0.00165 aver reward:17.40000 explot:0.01003\n",
      "global step:310590 episode :149/210 aver loss:0.00162 aver reward:17.50000 explot:0.01003\n",
      "global step:313251 episode :150/210 aver loss:0.00160 aver reward:16.70000 explot:0.01003\n",
      "global step:315219 episode :151/210 aver loss:0.00158 aver reward:16.10000 explot:0.01003\n",
      "global step:317133 episode :152/210 aver loss:0.00156 aver reward:16.40000 explot:0.01003\n",
      "global step:319655 episode :153/210 aver loss:0.00156 aver reward:15.80000 explot:0.01002\n",
      "global step:321817 episode :154/210 aver loss:0.00157 aver reward:15.90000 explot:0.01002\n",
      "global step:323512 episode :155/210 aver loss:0.00157 aver reward:16.10000 explot:0.01002\n",
      "global step:325713 episode :156/210 aver loss:0.00158 aver reward:15.60000 explot:0.01002\n",
      "global step:327633 episode :157/210 aver loss:0.00158 aver reward:15.40000 explot:0.01002\n",
      "global step:329760 episode :158/210 aver loss:0.00156 aver reward:15.60000 explot:0.01002\n",
      "global step:331666 episode :159/210 aver loss:0.00154 aver reward:15.90000 explot:0.01002\n",
      "global step:333678 episode :160/210 aver loss:0.00152 aver reward:16.40000 explot:0.01001\n",
      "global step:335737 episode :161/210 aver loss:0.00148 aver reward:16.70000 explot:0.01001\n",
      "global step:337866 episode :162/210 aver loss:0.00145 aver reward:16.40000 explot:0.01001\n",
      "global step:339645 episode :163/210 aver loss:0.00140 aver reward:17.00000 explot:0.01001\n",
      "global step:342721 episode :164/210 aver loss:0.00136 aver reward:16.20000 explot:0.01001\n",
      "global step:344939 episode :165/210 aver loss:0.00133 aver reward:15.70000 explot:0.01001\n",
      "global step:346631 episode :166/210 aver loss:0.00131 aver reward:16.30000 explot:0.01001\n",
      "global step:349018 episode :167/210 aver loss:0.00131 aver reward:15.70000 explot:0.01001\n",
      "global step:350821 episode :168/210 aver loss:0.00133 aver reward:16.00000 explot:0.01001\n",
      "global step:352658 episode :169/210 aver loss:0.00134 aver reward:16.10000 explot:0.01001\n",
      "global step:354440 episode :170/210 aver loss:0.00132 aver reward:16.40000 explot:0.01001\n",
      "global step:356356 episode :171/210 aver loss:0.00134 aver reward:16.20000 explot:0.01001\n",
      "global step:358084 episode :172/210 aver loss:0.00135 aver reward:16.60000 explot:0.01001\n",
      "global step:360164 episode :173/210 aver loss:0.00138 aver reward:16.10000 explot:0.01001\n",
      "global step:362042 episode :174/210 aver loss:0.00140 aver reward:17.20000 explot:0.01001\n",
      "global step:363669 episode :175/210 aver loss:0.00140 aver reward:17.70000 explot:0.01001\n",
      "global step:366180 episode :176/210 aver loss:0.00142 aver reward:16.70000 explot:0.01000\n",
      "global step:367953 episode :177/210 aver loss:0.00142 aver reward:17.30000 explot:0.01000\n",
      "global step:370060 episode :178/210 aver loss:0.00141 aver reward:17.10000 explot:0.01000\n",
      "global step:372098 episode :179/210 aver loss:0.00139 aver reward:16.60000 explot:0.01000\n",
      "global step:373872 episode :180/210 aver loss:0.00138 aver reward:16.80000 explot:0.01000\n",
      "global step:375989 episode :181/210 aver loss:0.00137 aver reward:16.80000 explot:0.01000\n",
      "global step:377802 episode :182/210 aver loss:0.00135 aver reward:16.70000 explot:0.01000\n",
      "global step:379569 episode :183/210 aver loss:0.00132 aver reward:17.40000 explot:0.01000\n",
      "global step:381446 episode :184/210 aver loss:0.00127 aver reward:17.40000 explot:0.01000\n",
      "global step:383197 episode :185/210 aver loss:0.00124 aver reward:17.40000 explot:0.01000\n",
      "global step:384848 episode :186/210 aver loss:0.00120 aver reward:18.40000 explot:0.01000\n",
      "global step:386542 episode :187/210 aver loss:0.00116 aver reward:18.60000 explot:0.01000\n",
      "global step:388228 episode :188/210 aver loss:0.00112 aver reward:19.00000 explot:0.01000\n",
      "global step:390218 episode :189/210 aver loss:0.00112 aver reward:19.00000 explot:0.01000\n",
      "global step:392713 episode :190/210 aver loss:0.00111 aver reward:18.10000 explot:0.01000\n",
      "global step:394655 episode :191/210 aver loss:0.00111 aver reward:18.50000 explot:0.01000\n",
      "global step:396345 episode :192/210 aver loss:0.00110 aver reward:18.70000 explot:0.01000\n",
      "global step:398266 episode :193/210 aver loss:0.00109 aver reward:18.50000 explot:0.01000\n",
      "global step:400030 episode :194/210 aver loss:0.00108 aver reward:18.60000 explot:0.01000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step:401990 episode :195/210 aver loss:0.00107 aver reward:18.10000 explot:0.01000\n",
      "global step:403618 episode :196/210 aver loss:0.00107 aver reward:18.10000 explot:0.01000\n",
      "global step:405604 episode :197/210 aver loss:0.00107 aver reward:17.80000 explot:0.01000\n",
      "global step:407233 episode :198/210 aver loss:0.00107 aver reward:17.90000 explot:0.01000\n",
      "global step:409486 episode :199/210 aver loss:0.00107 aver reward:18.00000 explot:0.01000\n",
      "global step:411548 episode :200/210 aver loss:0.00106 aver reward:18.60000 explot:0.01000\n",
      "global step:413973 episode :201/210 aver loss:0.00106 aver reward:18.00000 explot:0.01000\n",
      "global step:416500 episode :202/210 aver loss:0.00109 aver reward:17.20000 explot:0.01000\n",
      "global step:418278 episode :203/210 aver loss:0.00110 aver reward:17.20000 explot:0.01000\n",
      "global step:420502 episode :204/210 aver loss:0.00112 aver reward:16.90000 explot:0.01000\n",
      "global step:422399 episode :205/210 aver loss:0.00113 aver reward:17.20000 explot:0.01000\n",
      "global step:424328 episode :206/210 aver loss:0.00114 aver reward:16.90000 explot:0.01000\n",
      "global step:425986 episode :207/210 aver loss:0.00114 aver reward:17.20000 explot:0.01000\n",
      "global step:427674 episode :208/210 aver loss:0.00115 aver reward:17.10000 explot:0.01000\n",
      "global step:429304 episode :209/210 aver loss:0.00113 aver reward:17.70000 explot:0.01000\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "import gym\n",
    "env = make_atari('PongNoFrameskip-v4') # only use in no frameskip environment\n",
    "env = wrap_deepmind(env, scale = False, frame_stack=True )\n",
    "\n",
    "load_model = False\n",
    "run_dqn = DDQN_priority(args, env, load_model)\n",
    "losses, rewards = run_dqn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss and rewards\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_(losses, rewards):\n",
    "    plt.figure()\n",
    "    plt.title('rewards')\n",
    "    plt.plot(list(range(len(rewards))), rewards)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('loss')\n",
    "    plt.plot(list(range(len(losses))),losses)\n",
    "    plt.show()\n",
    "\n",
    "plot_(losses, rewards) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
